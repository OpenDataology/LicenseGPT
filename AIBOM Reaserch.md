# 目录
1. [中国在AIGC领域的相关法律](#1-中国在aigc领域的相关法律)
   - [《网络安全技术 生成式人工智能服务安全基本要求（TC260-003）》](#11-网络安全技术-生成式人工智能服务安全基本要求tc260-003)
   - [《互联网信息服务深度合成管理规定》](#12-互联网信息服务深度合成管理规定)
   - [《生成式人工智能服务管理暂行办法》](#13-生成式人工智能服务管理暂行办法)
   - [《互联网信息服务算法推荐管理规定》](#14-互联网信息服务算法推荐管理规定)
2. [美国](#2-美国)
3. [欧盟](#3-欧盟)
4. [AIGC案例情况](#aigc案例情况)
   - [国内](#1-国内)
   - [海外](#2-海外)
5. [AI数据潜在的风险洞察部分](#ai数据潜在的风险洞察部分)
    - [AI数据合规的法律](#1-ai数据合规的法律)
    - [版权风险](#2-版权风险)
    - [版权风险：地区差异在执法严格度和处罚力度上有显著不同](#3-版权风险：地区差异在执法严格度和处罚力度上有显著不同)
    - [内容安全风险：涉政涉敏数据不当用于模型训练可能导致公众事件，严重者造成服务下线](#4-内容安全风险：涉政涉敏数据不当用于模型训练可能导致公众事件，严重者造成服务下线)
    - [个人隐私风险：数据飞轮、多模态带来个人隐私的新挑战](#5-个人隐私风险：数据飞轮、多模态带来个人隐私的新挑战)

# AIGC立法情况

## 1. 中国在AIGC领域的相关法律

### 1.1 《网络安全技术 生成式人工智能服务安全基本要求（TC260-003）》
#### (1) 语料安全要求
- **来源安全要求**:
  - **(a)** 来源管理：安全评估+核验，不良率≦5%。
  - **(b)** 不同来源搭配；来源可追溯。
  - **(c)** 使用商业语料的合同及审核要求。
  - **(d)** 依法及政策要阻断的信息，不作语料。

- **内容安全要求**:
  - **(a)** 内容过滤：关键词+分类模型+人工抽检。
  - **(b)** 知识产权：设置知产负责人，建立知产管理策略，训练前知产风险识别，投诉举报途径，用户协议知产风险告知及责任分配，即使更新知产策略，具备公开摘要，支持语料及知产情况查询的知产措施。
  - **(c)** 个人信息同意要求。

- **标注安全要求**:
    - **(a)** 标注人员。
    - **(b)** 标注规则。
    - **(c)** 标注内容准确性。
    - **(d)** 宜对安全性标注数据隔离存储。

#### (2) 模型安全要求
- **(a)** 如需基于第三方基础模型提供服务，应使用已备案的基础模型。
- **(b)** 模型生成内容安全要求。
- **(c)** 生成内容准确性方面要求。
- **(d)** 生成内容可靠性方面要求。

#### (3) 安全措施要求
- **(a)** 模型适用人群、场合、用途方面的要求。
- **(b)** 服务透明度方面的要求。
- **(c)** 当收集使用者输入信息用于训练时的要求。
- **(d)** 图片，视频等内容标识方面的要求。
- **(e)** 训练、推理所采用的计算系统方案的要求。
- **(f)** 接受公众或使用者投诉举报方面。
- **(g)** 向使用者提供服务方面。
- **(h)** 模型更新、升级方面。
- **(i)** 服务稳定，持续方案的要求。

#### (4) 其他要求
- 关键词库；生成内容测试题库; 据答测试题库; 分类模型。

#### (5) 安全评估要求
- 评估方法；语料安全评估；生成内容安全评估；问题拒答评估。

#### (6) 语料及生成内容的主要安全风险（共31种）
- **1** 包含违反社会主义核心价值观的内容（共8种）。
- **2** 包含歧视性内容（共9种）。
- **3** 商业违法违规（共5种，含侵犯他人知识产权）。
- **4** 侵犯他人合法权益（共7种，含侵害他人肖像权）。
- **5** 无法满足特定服务类型的安全需求（共2种）。

### 违反后果
基本要求未规定违反后果，从行为来看，如不满足第9章的要求，可能无法顺利获得备案或者影响相关主管部门对AI服务安全水平的评价。


### 1.2《互联网信息服务深度合成管理规定》
### 主要要求
#### 针对提供者：
- **(a)** 不得利用算法推荐服务从事禁止性活动，传播禁止性信息，应当采取措施防范和地址传播不良信息。
- **(b)** 应当落实算法安全主体责任，建立健全算法机制机理审核，科技伦理审查，用户注册，信息发布审核，数据安全和个人信息保护等管理制度和技术措施，制定并公开算法推荐服务相关规则，配备相应的专业人员和技术支撑。
- **(c)** 定期审核，评估，验证算法机制机理模型，数据和应用结果等，不得设置诱导用户沉迷，过度消费等违法违背伦理道德的算法模型。
- **(d)** 加强信息安全管理，建立健全识别违法和不良信息的特征库。发现未作显著标识的算法生成合成信息的，应当做出显著标识后，方可传输。发现违法信息，停止传输，消除等措施，并向网信和有关部门报告。发现不良信息的，应该按照网络信息内容生态治理有关规定处置。
- **(e)** 应当加强用户模型和用户标签管理，不得将违法和不良信息关键词记入用户兴趣点或作为用户标签并据以推送信息。
- **(f)** 应该加强算法推荐服务版面页面生态管理，建立完善人工干预和用户自主选择机制。
- **(g)** 不得利用算法干预信息呈现，实施影响网络舆论或规避监管。
- **(h)** 不得利用算法实施垄断和不正当竞争。
- **(i)** 用户权益保护相关要求（告知，不针对个人特征，允许用户选择，删除等）。
- **(j)** 应当设置便捷的申诉，投诉及举报及处理机制。
- **(k)** 具有舆论属性或社会动员能力的算法推荐服务提供者应在提供服务之日起10个工作日内通过互联网信息服务算法备案系统填报信息履行备案手续。备案信息发生变更的，10个工作日办理变更。终止服务的，20个工作日内办理注销备案并做出妥善安排。材料齐全的，国家和省级网信办30个工作日内备案发放备案编号并公示。不齐全的，不予备案，30工作日通知备案人并说明理由。
- **(l)** 完成备案的，应在对外提供服务的网页等界面显著页面公示备案号及链接。
- **(m)** 具有舆论属性或者社会动员能力的算法推荐服务提供者应当按照国家有关规定开展安全评估。

### 违反后果
1. 使用者有权投诉举报。
2. 网信办会同有关部门开展安全评估和监督检查，提供者应依法留存网络日志，配合安全评估和监督检查。
3. 提供者违反部分规定的，按照适用现有法律法规处罚。没有规定的，有关主管部门可警告，通报批评，责令限期整改，拒不改正或严重的，责令暂停更新，处一万以上十万以下罚款。
4. 不正当手段取得备案的，国家和省级网信办予以撤销备案，警告，通报批评，情节严重的，责令暂停更新信息，并处1万以上10万以下罚款。
5. 终止服务未办理注销备案手续的，或严重违法被关闭网站，吊销业务许可证或营业执照的，由国家和省级网信办予以注销备案。


### 1.3《生成式人工智能服务管理暂行办法》
### 主要要求

#### 针对提供者和使用者：
1. 不得生成法律法规禁止的内容；采取有效措施防止产生歧视。
2. 尊重知识产权，保守商密，不得利用算法等优势实施垄断和不正当竞争。
3. 提升服务的透明度，确保生成内容的准确性和可靠性。

#### 仅针对提供者：
- **(a)** 依法开展数据处理活动，使用具有合法来源的数据和基础模型，不得侵害他人知识产权，涉及个人信息应经许可或符合法律法规。
- **(b)** 在研发过程中进行数据标注时，应制定清晰、具体、可操作性的标注规则；开展数据标注质量评估和培训。
- **(c)** 依法承担网络信息内容生产者责任，履行网络信息安全义务，履行个人信息保护义务。
- **(d)** 与注册其服务的使用者签订服务协议，明确权利与义务。
- **(e)** 明确公开服务的适用人群、场合、用户，指导使用者理性依法使用，防范未成年人沉迷。
- **(f)** 对使用者的输入信息和使用记录依法保护。
- **(g)** 根据《互联网信息服务深度合成管理规定》，对图片、视频等生成内容进行标识。
- **(h)** 发现违法内容时，停止生成、传输，消除等处理，并优化训练等措施整改；向有关主管部门报告。若发现使用者利用服务从事违法活动，应依法依约采取警示、限制功能、暂停或停止向其提供服务等处置措施，并保持有关记录。
- **(i)** 建立健全投诉举报机制，公布处理流程和反馈时限。
- **(j)** 提供具有舆论属性或者社会动员能力的生成式人工智能服务时，应开展安全评估，并按《互联网信息服务算法推荐管理规定》履行算法备案、变更、注销手续。

### 违反后果
1. 使用者有权投诉举报。
2. 有关主管部门可以开展监督检查，提供者应予以配合，按要求提供训练数据来源、规模等。
3. 对源于境外向境内提供生成式人工智能服务不符合规定的，国家网信部门应通知有关机构采取技术措施和其他必要措施。
4. 提供者违反本规定的，按照适用现有法律法规处罚。没有规定的，有关主管部门可通报批评，责令限期整改，拒不改正或严重的，责令暂停服务。

 
### 1.4《互联网信息服务算法推荐管理规定》
### 主要要求
1. **通用规定**:
   - 任何组织和个人不得利用深度合成服务制作、复制、发布、传播法律法规禁止的信息。
   - 不得利用服务从事危害国家安全、侵犯他人合法权益等禁止活动。
   - 不得采取技术措施删除、篡改、隐匿本规定下的深度合成标识。

2. **针对提供者和使用者**:
   - 不得利用深度合成服务制作、复制、发布、传播虚假新闻信息。
   - 转载基于深度合成服务制作发布的新闻信息时，应依法转载互联网新闻信息稿源单位发布的新闻信息。

3. **具体于提供者**:
   - **(a)** 应落实信息安全主体责任，建立健全用户注册、算法机制机理审核、科技伦理审查、信息发布审核、数据安全、个人信息保护等管理制度，具有安全可控的技术保障措施。
   - **(b)** 制定并公开管理规则、平台公约，完善服务协议，依法依约履行管理责任，以显著方式提示深度合成服务技术支持者和使用者承担信息安全义务。
   - **(c)** 基于电话、身份证、统一社会信用码或国家网络身份认证公共服务等方式，对使用者进行实名认证，不得向未进行实名认证的使用者提供信息发布服务。
   - **(d)** 加强深度合成内容管理，采取技术或人工方式对输入数据和合成结果进行审核。建立用于识别违法和不良信息的特征库，记录并留存相关网络日志。依法处置违法和不良信息，并向网信部门和有关主管部门报告。
   - **(e)** 建立健全辟谣机制，及时采取辟谣措施，保存有关记录并向网信和有关部门报告。
   - **(f)** 设置便捷的用户申述和公众投诉、举报及处理机制。
   - **(g)** 对使用其服务生成或编辑的信息内容，采取技术措施添加不影响用户使用的标识，并依法保存日志信息。
   - **(h)** 对可能导致公众混淆误认的深度合成服务，在合理位置区域进行显著标识，并向公众提示深度合成情况。
   - **(i)** 提供非上述规定的深度合成服务时，提供显著标识功能，并提示使用者可以进行显著标识。
   - **(j)** 开发上线具有舆论属性或社会动员能力的新产品、新应用、新功能时，按规定开展安全评估。

4. **针对提供者和技术支持者**:
   - **(a)** 加强训练数据管理，保障训练数据安全。对包括个人信息的训练数据，遵守个人信息保护规定。
   - **(b)** 定期审核、评估、验证生成合成类算法机制机理。
   - **(c)** 对具有特定功能的模型、模板等工具，依法自行或委托专业机构开展安全评估。

5. **针对应用商店等应用分发平台**:
   - 落实上架审核、日常处理、应急处置等安全管理责任，核验深度合成类应用程序的安全评估、备案等情况；对违反规定的，应采取不予上架、暂停服务、下架等处置措施。

### 违反后果
1. 网信、电信、公安部门可以开展监督检查，提供者应予以配合。
2. 若发现深度合成服务存在较大信息安全风险，可要求提供者和技术支持者采取停更、停账号等措施。
3. 提供者违反本规定的，按照适用现有法律法规处罚；造成严重后果的，依法从重处罚。


## 2. 美国
- 美国版权局 2023.03《 Copyright Registration Guidance: Works Containing Material Generated by Artificial Intelligence》
- 美国版权局的实际操作：
  - 图片利用AI工具Midjourney自动生成
  - 配上文字和组合并申请整书和单页的版权登记。

## 3. 欧盟
- 适用范围：在欧盟境内提供AI系统的提供者，不论提供者所在国家。 位于欧盟境内的AI系统使用者，AI系统的提供者和使用者在第三国，但输出在欧盟境内使用。
- 分层管控机制：主要关注AI可能引发的风险并分层级管控。
- 议会版本对开源软件的有限排除：免费和开源软件许可证下的AI组件不适用本法，除非被提供者作为高风险AI系统或Title 11或IV组件投入市场或提供服务。基础模型不适用该排除规则。（对开源软件的排除规则仍不清晰）

## AIGC案例情况

### 1. 国内
- **菲林律师事务所诉百度公司**
  - 案情：原告利用“威科先行”生成一篇文章，被告将该文章搬运至其“百家号”平台。原告认为该行为侵犯其作品信网传播权。
  - 进展/结果：涉案分析报告不构成著作权法下的作品；但报告的文字内容构成作品。原告索赔10560元，法院判赔1560元。

- **腾讯公司诉盈讯公司**
  - **案情**：原告利用“Dreamwriter”生成一篇文章，被告在其自营网站上发布标题及内容相同的文章。原告认为该行为侵犯其作品信网传播权侵权，构成不正当竞争。
  - **进展/结果**：涉案文章构成著作权法下的作品。原告索赔19000元，法院判赔1500元。

- **“AI文生图”著作权第一案**
  - **案情**：原告利用“Stable Diffusion”生成一张AI图片，被告在其百家号平台上使用了该图片。原告认为该行为侵犯其署名权及作品的信网传播权。
  - **进展/结果**：涉案图片构成著作权法下的作品。原告索赔5000元，法院判赔500元。

- **新创华诉某AI公司**
  - **案情**：原告新创华公司拥有“奥特曼”动漫形象的著作权独占授权。原告发现被告经营的文生图网站Tab生成的奥特曼图片与原告作品相似，认为被告未经授权使用其作品训练AI，生成相似图片并获取收益，侵犯其著作权。
  - **进展/结果**：涉案图片侵犯原告作品著作权。原告索赔300000元，法院判赔10000元。


### 2 海外
- **法国出版商联合体 & 法国竞争管理局 v. Google**
  - **涉诉产品**：法国当地法院
  - **进展/结果**：谷歌被发现违反了透明义务，没有向媒体和新闻机构告知Gemini以及之前的 Bard使用其内容来构建其人工智能工具的情况。被法国监管机构处以2.5亿欧元罚款。

- **J. Doe 1 et al v. GitHub, Inc. et al**
  - **涉诉产品**：Copilot，codex
  - **进展/结果**：1，2022年12月，两案合并审理。2，2024年1月3日，法院做出了部分驳回动议的决定，原告可继续调整诉状。

- **Getty Images (US), Inc. v. Stability AI, Inc.**
  - **涉诉产品**：Stable Diffusion，DreamStudio
  - **进展/结果**：2023年3月29日，原告修改起诉书，将Stability UK列为共同被告。
    2023年5月2日，被告提出驳回动议，申请转移管辖。7月21日，原告要求听证。

- **Tremblay et al v. OpenAI, INC. et al**
  - **涉诉产品**：ChatGPT
  - **进展/结果**：经原告请求，法院已认可该案与Silverman案系关联案件，一并处理。

- **Silverman et al v. OpenAI, Inc. et al**
  - **涉诉产品**：ChatGPT
  - **进展/结果**：该案在与Tremblay案合并审理后，2024年2月12日，法官批准了OpenAI的大部分动议，法官同意原告在3月13日之前修改他们的起诉书。

- **Kadrey et al v. Meta Platforms, Inc.**
  - **涉诉产品**：LLaMA模型
  - **进展/结果**：2023年9月18日，Meta提出驳回动议。
    2023年9月22日，法院批准了行政救济动议，将本案与Chabon一案关联起来。
    2023年11月20日，法院准予了被告提出的驳回动议，允许原告修改诉状。

- **Chabon et al v. OpenAI, Inc. et al**
  - **涉诉产品**：ChatGPT，LLaMA模型
  - **进展/结果**：2023年9月22日，法官下令要求诉OpenAI案与Tremblay案合并审理。2024年2月14日，法官驳回本案原告关于 ChatGPT 生成的内容侵犯其版权的诉请。
    2023年12月7日，法院同意Meta案与Kadrey案合并审理。

- **Authors Guild et al v. OpenAI Inc. et al**
  - **涉诉产品**：ChatGPT
  - **进展/结果**：2023年11月4日，原告修改诉状，将Microsoft列为共同被告。2024年2月16日， Microsoft独立于 OpenAI 提交答辩，否认训练过涉案模型，否认任何作品侵权。
    2024年3月4日，OpenAI提交答辩，辩称训练模型符合版权材料的典型转化性合理使用。

- **Huckabee et al v. Meta Platforms, Inc. et al**
  - **涉诉产品**：The Pile
  - **进展/结果**：2023年11月15日， Bloomberg称其行为是合理使用，申请驳回原告所有诉请，2023年11月22日，原告提交了对Bloomberg驳回动议意向书的回应。
    2023年11月26日，原告自愿驳回对EleutherAI的起诉。
    2023年12月28日，法院驳回了原告对Meta和Microsoft的所有指控，并将这些指控转移到加州北区法院，对Bloomberg的指控将保留在纽约南区。
    2024年1月24日，原告提交对Bloomberg修改后的起诉书。

- **Alter et al v. OpenAI Inc. et al**
  - **涉诉产品**：ChatGPT
  - **进展/结果**：原告于2023年11月21日起诉，目前案件尚未进入实质审查。

- **The New York Times Company v. Microsoft Corporation et al**
  - **涉诉产品**：ChatGPT，Bing Chat
  - **进展/结果**：原告于2023年12月27日起诉，目前案件尚未进入实质审查。

- **Basbanes et al v. Microsoft Corporation et al**
  - **涉诉产品**：ChatGPT
  - **进展/结果**：2024年1月23日，原告要求将本案与Authors Guild案合并。2024年2月5日，原告要求将本案与Alter案也合并审理。目前案件尚未进入实质审查。

- **The Intercept Media, Inc. v. OpenAI, Inc. et al**
  - **Raw Story Media, Inc. et al v. OpenAI Inc. et al**
  - **涉诉产品**：ChatGPT
  - **进展/结果**：原告于2024年2月28日起诉，目前案件尚未进入实质审查。

- **Nazemian et al v. NVIDIA Corporation**
  - **涉诉产品**：NeMo
  - **进展/结果**：原告于2024年3月8日起诉，目前案件尚未进入实质审查。


## AI数据潜在的风险洞察部分

### 1. AI数据合规的法律
- **欧盟：**
  - AI法案（2024）
  - CRA法案（2024）
  - GDPR（2016）
  - 网络安全法（2019）
  - 平等指令（2000、2006）
  - 版权指令（2019）
  - 产品责任指令（1985、2024）
  - AI责任指令（2022）

- **中国：**
  - 生成式人工智能服务管理暂行办法（2023）
  - 互联网信息服务算法推荐管理规定（2021）
  - 互联网信息服务深度合成管理规定（2022）
  - 互联网新闻信息服务新技术新应用安全评估管理规定（2017）
  - 具有舆论属性或社会动员能力的互联网信息服务安全评估规定（2018）
  - 网络安全法（2016）
  - 个人信息保护法（2021）
  - 数据安全法（2021）
  - 著作权法（2020）

### 2. 版权风险:法规要求数据内容都获得授权，相关技术标准还在制定中，当前评估项要求企业有对数据版权合规的管理过程和相关证据

#### 欧盟、中国法规对版权相关要求的描述：

- **欧盟AI法**:
  - 透明度要求：GPAI模型必须满足某些透明度要求，包括遵守欧盟著作权法和发布用于培训的内容的详细摘要。生成式人工智能必须披露他们是否在系统中使用了受版权保护的材料。

- **欧盟数字单一市场版权指令**:
  - 版权材料的使用：使用了未经授权的版权材料，如新闻出版物、音乐、视频等，可能侵犯了权利人的复制权、邻接权或传播权。
  - 在线内容共享服务提供者的责任：《版权指令》第17条特别规定要求平台尽最大努力与权利人达成许可协议，或者尽最大努力阻止未经授权的内容出现在平台上。

- **生成式人工智能管理暂行办法**:
  - 预训练和优化训练的合法性：《生成式人工智能服务管理暂行办法》规定，生成式人工智能服务提供者应依法开展预训练、优化训练等活动，涉及知识产权的，不得侵害他人依法享有的知识产权（著作权属于知识产权的一种）。

- **中国著作权法**:
  - 侵权责任：侵犯著作权或相关权利的，侵权人应赔偿权利人的实际损失或违法所得。如果损失或违法所得难以计算，可参照权利使用费赔偿。故意侵权且情节严重的，赔偿额度可提高至一倍以上五倍以下。

#### 中国国标对版权相关要求的描述：

- **生成式人工智能预训练和优化训练数据安全规范（征求意见稿）**:
  - 应为数据中所有数据样本添加元数据内容：
  - 应对数据中的主要知识产权侵权风险进行识别并记录，例如数据中包含文学、艺术、科学作品的，重点识别数据的著作权侵权问题。

- **生成式人工智能服务安全基本要求（TC260-003）**:
  - 应设置语料以及生成内容的知识产权负责人，并建立知识产权管理策略；
  - 语料中包含文学、艺术、科学作品的，应重点识别语料以及生成内容中的著作权侵权问题；
  - 应及时根据国家政策以及第三方投诉情况更新知识产权相关策略；
  - 宜具备以下知识产权措施：
    - 公开语料中涉及知识产权部分的摘要信息；
    - 在投诉举报渠道中支持第三方就语料使用情况以及相关知识产权情况进行查询。

#### 实例：斯坦福大学基础大模型遵守欧盟AI法的评估
- 斯坦福大学为了遵守欧盟AI法，进行了详细的透明度评估，以确保其基础大模型在使用过程中透明地披露了使用的数据源和处理方法，包括哪些数据是受版权保护的材料，以及如何获得相应的授权。

### 3. 版权风险：地区差异在执法严格度和处罚力度上有显著不同

#### 欧盟：严格执行高规格处罚
- **实例**：2024年3月，Google因使用法国出版商和新闻机构的内容未经同意训练其AI聊天机器人“Gemini”（原名“Bard”），违反了欧洲联盟版权指令，结果被处以高达2.5亿欧元的罚款。

#### 美国：以产业发展为优先，判罚谨慎
- **实例**：2024年3月，涉及OpenAI等公司，使用Common Crawl和WebText数据集训练大模型，这些数据集包含大量纽约时报的高质量原创文章。这一行为在法庭上被指控可能侵犯《纽约时报》的多项版权。

#### 中国：处罚较轻，但已开始注重版权保护
- **实例**：2024年3月，广州互联网法院作出判决，这是全球范围内首例生成式AI服务侵犯他人著作权的生效判决。被告使用知名IP“奥特曼”作为训练数据生成相似图片并获得收益，最终被判赔偿1万人民币并要求下架违法服务。

### 4. 内容安全风险：涉政涉敏数据不当用于模型训练可能导致公众事件，严重者造成服务下线
AI在处理或生成涉政涉敏信息时的不当行为可能导致严重的社会和法律后果，包括服务的暂停或下线。此类数据的处理需要格外谨慎，因为不仅违反法律法规，即使合法使用也可能引发广泛的社会影响和负面舆论。

#### 案例分析：

- **案例1：XM AI助理**
  - **背景**：XM AI助理在回答敏感问题时表现出不当行为，随后过度纠正，导致其在任何问题上都表达极端的政治立场，引起国际媒体的负面报道。
  - **后果**：产生了国际上的恶劣影响，并对公司形象造成损害。

- **案例2：KDXF AI学习机**
  - **背景**：2023年10月，KDXF AI学习机在处理敏感内容时涉嫌侮辱前国家领导人，遭到举报。
  - **后果**：该事件导致公司股票市值蒸发120亿，且公司被官方约谈并要求整改。

- **案例3：某国内AI助手**
  - **背景**：该AI助手在解释“918”事件相关问题时表现不当，未能正确处理敏感历史内容。
  - **后果**：不当解释引起用户在网络上的大量投诉，造成了广泛的负面影响。

这些案例表明，即使AI技术高度发达，对涉政涉敏内容的管理仍需谨慎，避免触发法律争议和社会不安。

### 5. 个人隐私风险：数据飞轮、多模态带来个人隐私的新挑战

随着AI技术的发展，特别是在个性化应用和多模态交互方面，个人隐私面临着新的风险。以下是一些涉及个人隐私的AI应用示例，以及它们可能引发的隐私问题。

#### 应用场景与隐私风险：

- **个性化壁纸**:
  - **人像ID保持**：持续追踪和识别用户的面部特征。
  - **服饰ID保持**：分析和记录用户的穿着习惯。
  - **动态壁纸**：实时更新壁纸可能会无意中捕捉并展示敏感个人信息。

- **图片后期制作**:
  - **一键换脸**：在未经用户同意的情况下，使用用户的面部图像进行合成和共享，可能侵犯肖像权。
  - **表情融合**：合成表情或改变表情可能涉及敏感情绪数据的使用和分析。

- **虚拟摄影**:
  - **迭代照片编辑**：对用户照片的重复编辑和使用可能未经用户同意，且存储的数据可能被不当使用。
  - **AIGC照片生成**：生成的图片可能包含个人数据，且生成过程中的数据使用需要严格监管。

#### 具体事件案例：

- **OpenAI隐私泄露问题**:
  - **事件描述**：
    - **2023年3月20日**：ChatGPT因泄露用户聊天记录而被意大利数据保护局依据GDPR规定暂时禁用，并处以2000万欧元罚款。
    - **2024年初**：OpenAI发布的多模态大模型Sora被发现可能违反GDPR，意大利数据保护局对此启动了新一轮调查，再次将OpenAI推入隐私争议的风暴中。
  - **意大利数据保护局要求**：
    - 确定算法的训练方法。
    - 明确训练算法所使用的数据类型和处理方式。
    - 确认是否涉及任何个人数据的处理。
    - 查明是否收集关于宗教或哲学信仰、政治观点、遗传数据、健康等敏感信息。

这些案例显示，随着技术的不断进步，保护个人隐私的重要性日益增加，同时也凸显了相关法律法规的应用和执行的必要性。
